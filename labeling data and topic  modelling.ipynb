{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb=pd.read_csv('C:/Users/Administrator/Desktop/Term 3/Unstructured Data/datasets/imdb_sentiment.csv')\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader (Valence Aware Dictionary and Sentiment Reasoner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i love india')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Sentence Polarity = No: of Positive words - No: of negative words\n",
    "2. compound score range: -1 to +1 (overall score for the sentence)\n",
    "3. for eg: love=3.2, like=1.5, bad=-2.5, hate=-2.7, the overall score will be given as, 3.2+1.5-2.5-2.7\n",
    "4. Normalisation = score/(score^2 + alpha(which is usually '15'))\n",
    "5. So the normalisation(compound) score for love is, 3.2/np.sqrt(3.2**2+15)=0.636\n",
    "6. only for calculating percentage of positive and negative, neutral values are given the value of 1 and to compensate 1 is added to score of positive\n",
    "7. Pos = 4.2 (3.2 + 1)\n",
    "   Neg = 0\n",
    "   Neu = 1\n",
    "       -----\n",
    "        5.2\n",
    "       -----\n",
    "8. % of pos score = 4.2/5.2 = 0.808\n",
    "9. % of neg score = 0/5.2 = 0\n",
    "10. for the sentence is, i love(3.2) india i hate(-2.7) apple\n",
    "11. Pos = 4.2 (3.2 + 1)\n",
    "    Neg = 3.7 (2.7 + 1)\n",
    "    Neu = 2\n",
    "         -----\n",
    "          9.9\n",
    "         -----\n",
    "12. % of pos score = 4.2/9.9 = 0.424\n",
    "13. % of neg score = 3.7/9.9 = 0.374\n",
    "14. % of neu score = 2/9.9 = 0.202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    compound=sentiment.polarity_scores(text)['compound']\n",
    "    if compound>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['sentiment_vader']=imdb['review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  A very, very, very slow-moving, aimless movie ...          0   \n",
       "1  Not sure who was more lost - the flat characte...          0   \n",
       "2  Attempting artiness with black & white and cle...          0   \n",
       "3       Very little music or anything to speak of.            0   \n",
       "4  The best scene in the movie was when Gerardo i...          1   \n",
       "\n",
       "   sentiment_vader  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941176470588235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(imdb['sentiment'],imdb['sentiment_vader'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSA (Latent Semantic Analysis)\n",
    "- LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- matrix factorization means finding the hidden features of 2 objects. Such as movie and user have genres as a hidden factor.\n",
    "- can create product catalogue\n",
    "- gensim expresses it in a compressed format\n",
    "- compressed data will be 1% of the actual data because the actual data had 99% zeros and no zeros is 1%. It reduces RAM space\n",
    "- id's are given to the words in this compressed format internally. It saves more space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000HDJXNA</td>\n",
       "      <td>1</td>\n",
       "      <td>What I recieved is not what is pictured here O...</td>\n",
       "      <td>12 26, 2012</td>\n",
       "      <td>A29YXBFTD7QUP3</td>\n",
       "      <td>HHA</td>\n",
       "      <td>Buyer be ware</td>\n",
       "      <td>1.356480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006KKS7XQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent unit and a pretty simple install usi...</td>\n",
       "      <td>09 20, 2013</td>\n",
       "      <td>A3IMTXFYD7CGDN</td>\n",
       "      <td>Peter W. George \"soyflakeman\"</td>\n",
       "      <td>high quality without high price</td>\n",
       "      <td>1.379635e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002NP8XJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm enjoying this keyboard, I'm getting anothe...</td>\n",
       "      <td>08 31, 2010</td>\n",
       "      <td>AXNOW20FQKHVW</td>\n",
       "      <td>B. Hayashi</td>\n",
       "      <td>Superb keyboard + solution for slow wake up an...</td>\n",
       "      <td>1.283213e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000EITTLE</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall, this is a fantastic camera that I'm e...</td>\n",
       "      <td>02 3, 2008</td>\n",
       "      <td>A10KCAK279LO0W</td>\n",
       "      <td>mmcwatters \"macdadi80\"</td>\n",
       "      <td>One qualm: not great in low light</td>\n",
       "      <td>1.201997e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006CRXK4S</td>\n",
       "      <td>5</td>\n",
       "      <td>These work very well with mySamsung PN64D7000 ...</td>\n",
       "      <td>01 28, 2012</td>\n",
       "      <td>A19XXLMZXR764J</td>\n",
       "      <td>S. Garfinkle</td>\n",
       "      <td>Work great, fit well</td>\n",
       "      <td>1.327709e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000HDJXNA        1  What I recieved is not what is pictured here O...   \n",
       "1  B006KKS7XQ        5  Excellent unit and a pretty simple install usi...   \n",
       "2  B002NP8XJ0        5  I'm enjoying this keyboard, I'm getting anothe...   \n",
       "3  B000EITTLE        4  Overall, this is a fantastic camera that I'm e...   \n",
       "4  B006CRXK4S        5  These work very well with mySamsung PN64D7000 ...   \n",
       "\n",
       "    reviewTime      reviewerID                   reviewerName  \\\n",
       "0  12 26, 2012  A29YXBFTD7QUP3                            HHA   \n",
       "1  09 20, 2013  A3IMTXFYD7CGDN  Peter W. George \"soyflakeman\"   \n",
       "2  08 31, 2010   AXNOW20FQKHVW                     B. Hayashi   \n",
       "3   02 3, 2008  A10KCAK279LO0W         mmcwatters \"macdadi80\"   \n",
       "4  01 28, 2012  A19XXLMZXR764J                   S. Garfinkle   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                      Buyer be ware    1.356480e+09  \n",
       "1                    high quality without high price    1.379635e+09  \n",
       "2  Superb keyboard + solution for slow wake up an...    1.283213e+09  \n",
       "3                  One qualm: not great in low light    1.201997e+09  \n",
       "4                               Work great, fit well    1.327709e+09  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon=pd.read_csv('C:/Users/Administrator/Desktop/Term 3/Unstructured Data/datasets/amazon_reviews_big.csv')\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What I recieved is not what is pictured here O...\n",
       "1    Excellent unit and a pretty simple install usi...\n",
       "2    I'm enjoying this keyboard, I'm getting anothe...\n",
       "3    Overall, this is a fantastic camera that I'm e...\n",
       "4    These work very well with mySamsung PN64D7000 ...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon['reviewText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=amazon['reviewText'].fillna(' ').str.lower()\n",
    "docs=docs.str.replace('[^a-z ]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean=[]\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['','work','use','one','get','great'])\n",
    "for doc in docs:\n",
    "    words=doc.split(' ')\n",
    "    words_clean=[stemmer.stem(word) for word in words if word not in stopwords]\n",
    "    words_clean=[word for word in words_clean if word not in stopwords]\n",
    "    docs_clean.append(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reciev',\n",
       " 'pictur',\n",
       " 'advert',\n",
       " 'vidio',\n",
       " 'cabl',\n",
       " 'job',\n",
       " 'need',\n",
       " 'look',\n",
       " 'high',\n",
       " 'qualiti',\n",
       " 'cabl',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'reciev',\n",
       " 'cheap',\n",
       " 'thin',\n",
       " 'flimsi',\n",
       " 'cabl',\n",
       " 'gold',\n",
       " 'plate',\n",
       " 'anyth',\n",
       " 'els',\n",
       " 'claim',\n",
       " 'bait',\n",
       " 'switch',\n",
       " 'mistak',\n",
       " 'order',\n",
       " '',\n",
       " '',\n",
       " 'know',\n",
       " 'attempt',\n",
       " 'contact',\n",
       " 'sender',\n",
       " 'find',\n",
       " 'contact',\n",
       " 'seller',\n",
       " 'told',\n",
       " 'contact',\n",
       " 'amazoncom',\n",
       " 'amazoncom',\n",
       " 'good',\n",
       " 'enough',\n",
       " 'give',\n",
       " '',\n",
       " 'refund',\n",
       " 'good',\n",
       " 'cabl',\n",
       " 'woth',\n",
       " '',\n",
       " '',\n",
       " 'need',\n",
       " 'run',\n",
       " 'wife',\n",
       " 'kareoke',\n",
       " 'tv',\n",
       " 'thing',\n",
       " 'els',\n",
       " 'would',\n",
       " 'sent',\n",
       " 'back',\n",
       " 'full',\n",
       " 'refund',\n",
       " 'im',\n",
       " 'surpris',\n",
       " 'item',\n",
       " 'still',\n",
       " 'list',\n",
       " 'high',\n",
       " 'grade',\n",
       " 'cabl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=gensim.corpora.Dictionary(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152950"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dictionary.values())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152950"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dictionary.keys())) #id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ''),\n",
       " (1, 'advert'),\n",
       " (2, 'amazoncom'),\n",
       " (3, 'anyth'),\n",
       " (4, 'attempt'),\n",
       " (5, 'back'),\n",
       " (6, 'bait'),\n",
       " (7, 'buy'),\n",
       " (8, 'cabl'),\n",
       " (9, 'cheap')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dictionary.keys(),dictionary.values()))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 5),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 3),\n",
       " (12, 2),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 2),\n",
       " (20, 1),\n",
       " (21, 2),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 2),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 2),\n",
       " (37, 2),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(docs_clean[0]) # this gives the frequency of an id repeating in the 0th index row of docs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the input structure for the gensim algorithm\n",
    "docs_bow=[]\n",
    "for doc in docs_clean:\n",
    "    bow=dictionary.doc2bow(doc)\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_bow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=gensim.models.LdaModel(docs_bow,id2word=dictionary,num_topics=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using a coherence model to determine num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.53621256), (1, 0.2111646), (3, 0.24869989)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_document_topics(docs_bow[1]) #document is mix of 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.9814274)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_document_topics(docs_bow[3]) #document is mix of 1 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2topic=pd.DataFrame(lda_model.get_document_topics(docs_bow[0]),columns=['Topic_no','Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2topic.sort_values('Prob',ascending=False).iloc[0]['Topic_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=[]\n",
    "for bow in docs_bow:\n",
    "    doc2topic=pd.DataFrame(lda_model.get_document_topics(bow),columns=['Topic_no','Prob'])\n",
    "    topic=doc2topic.sort_values('Prob',ascending=False)\n",
    "    topic=topic.iloc[0]['Topic_no']    \n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.021*\"case\" + 0.018*\"drive\" + 0.012*\"card\" + 0.009*\"like\" + 0.008*\"ipad\" + 0.007*\"fit\" + 0.007*\"well\" + 0.007*\"cover\" + 0.007*\"usb\" + 0.007*\"laptop\"'),\n",
       " (1,\n",
       "  '0.017*\"sound\" + 0.010*\"good\" + 0.010*\"qualiti\" + 0.009*\"speaker\" + 0.009*\"len\" + 0.008*\"like\" + 0.006*\"headphon\" + 0.006*\"look\" + 0.006*\"price\" + 0.006*\"realli\"'),\n",
       " (2,\n",
       "  '0.009*\"connect\" + 0.008*\"devic\" + 0.008*\"cabl\" + 0.007*\"tv\" + 0.006*\"would\" + 0.006*\"set\" + 0.006*\"unit\" + 0.006*\"time\" + 0.005*\"like\" + 0.005*\"problem\"'),\n",
       " (3,\n",
       "  '0.024*\"camera\" + 0.018*\"batteri\" + 0.010*\"charg\" + 0.008*\"good\" + 0.007*\"time\" + 0.007*\"would\" + 0.007*\"take\" + 0.007*\"like\" + 0.007*\"need\" + 0.007*\"price\"')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Perform topic modelling on ABCnews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news=pd.read_csv('C:/Users/Administrator/Desktop/Term 3/Unstructured Data/datasets/abcnews.csv')\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103665, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### too big records can take 1 lakh records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# news=news.sample(100000) \n",
    "# news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=news['headline_text'].fillna('').str.lower().replace('[^a-z ]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    aba decides against community broadcasting lic...\n",
       "1       act fire witnesses must be aware of defamation\n",
       "2       a g calls for infrastructure protection summit\n",
       "3             air nz staff in aust strike for pay rise\n",
       "4        air nz strike to affect australian travellers\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean=[]\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "for doc in docs:\n",
    "    words=doc.split(' ')\n",
    "    words=[stemmer.stem(word) for word in words if word not in stopwords]\n",
    "    words=[word for word in words if word not in stopwords]\n",
    "    docs_clean.append(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aba', 'decid', 'commun', 'broadcast', 'licenc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=gensim.corpora.Dictionary(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_bow=[]\n",
    "for docs in docs_clean:\n",
    "    bow=dictionary.doc2bow(docs)\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=gensim.models.LdaModel(docs_bow,id2word=dictionary,num_topics=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"wa\" + 0.020*\"elect\" + 0.015*\"sex\" + 0.013*\"test\" + 0.012*\"say\" + 0.011*\"turnbul\" + 0.010*\"child\" + 0.010*\"find\" + 0.010*\"labor\" + 0.009*\"get\"'),\n",
       " (1,\n",
       "  '0.017*\"state\" + 0.013*\"fight\" + 0.012*\"deal\" + 0.012*\"citi\" + 0.011*\"feder\" + 0.010*\"week\" + 0.010*\"talk\" + 0.010*\"three\" + 0.010*\"program\" + 0.009*\"say\"'),\n",
       " (2,\n",
       "  '0.018*\"sydney\" + 0.016*\"sa\" + 0.015*\"school\" + 0.014*\"say\" + 0.011*\"health\" + 0.011*\"could\" + 0.011*\"indigen\" + 0.011*\"chang\" + 0.011*\"tasmania\" + 0.010*\"fund\"'),\n",
       " (3,\n",
       "  '0.018*\"year\" + 0.017*\"hous\" + 0.016*\"woman\" + 0.016*\"show\" + 0.013*\"live\" + 0.013*\"market\" + 0.012*\"power\" + 0.012*\"miss\" + 0.010*\"victoria\" + 0.009*\"share\"'),\n",
       " (4,\n",
       "  '0.034*\"man\" + 0.027*\"charg\" + 0.027*\"court\" + 0.023*\"melbourn\" + 0.020*\"murder\" + 0.017*\"face\" + 0.015*\"death\" + 0.014*\"jail\" + 0.013*\"accus\" + 0.012*\"drug\"'),\n",
       " (5,\n",
       "  '0.019*\"open\" + 0.019*\"brisban\" + 0.017*\"make\" + 0.016*\"tasmanian\" + 0.016*\"hospit\" + 0.015*\"alleg\" + 0.014*\"time\" + 0.012*\"leagu\" + 0.011*\"run\" + 0.009*\"lose\"'),\n",
       " (6,\n",
       "  '0.031*\"trump\" + 0.021*\"australian\" + 0.021*\"govern\" + 0.018*\"day\" + 0.016*\"world\" + 0.016*\"north\" + 0.015*\"win\" + 0.014*\"donald\" + 0.014*\"one\" + 0.014*\"perth\"'),\n",
       " (7,\n",
       "  '0.032*\"australia\" + 0.024*\"queensland\" + 0.018*\"south\" + 0.015*\"new\" + 0.012*\"peopl\" + 0.011*\"australian\" + 0.011*\"west\" + 0.010*\"price\" + 0.010*\"marriag\" + 0.010*\"big\"'),\n",
       " (8,\n",
       "  '0.021*\"polic\" + 0.019*\"adelaid\" + 0.017*\"kill\" + 0.016*\"canberra\" + 0.016*\"fire\" + 0.015*\"crash\" + 0.015*\"women\" + 0.015*\"coast\" + 0.014*\"car\" + 0.014*\"nt\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis=pyLDAvis.gensim.prepare(lda_model,docs_bow,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
